{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cabeçalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.52.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrador\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "\n",
    "import openai\n",
    "\n",
    "OPENAI_API_KEY = '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'\n",
    "\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "  messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "  response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=messages,\n",
    "      temperature=0\n",
    "  )\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência de Sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O sentimento da avaliação é positivo, destacando a rapidez na entrega, o bom atendimento ao cliente e a qualidade do produto.\n"
     ]
    }
   ],
   "source": [
    "lamp_review = \"\"\"\n",
    "Comprei esta lâmpada para o meu quarto e ela tem espaço adicional e um preço acessível.\n",
    "Chegou rápido. O fio da lâmpada quebrou durante o transporte e a empresa enviou um novo rapidamente.\n",
    "Foi fácil de montar. Tive uma peça faltando, mas o suporte foi rápido em enviar a peça.\n",
    "A Lumina parece ser uma ótima empresa que se importa com seus clientes e produtos!\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Qual é o sentimento da seguinte avaliação de produto, delimitada por crases triplas?\n",
    "Texto da avaliação: ```{lamp_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positivo\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Qual é o sentimento da seguinte avaliação de produto, delimitada por crases triplas?\n",
    "Dê sua resposta como uma única palavra, \"positivo\" ou \"negativo\".\n",
    "Texto da avaliação: ```{lamp_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração de Emoções e Verificação de Condições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feliz, satisfeito, impressionado, grato, confiante\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Indentifique uma lista de emoções que o autor da seguinte avaliação está expressando.\n",
    "Inclua no máximo cinco itens na lista. Formate sua resposta como uma lista de palavras em minúsculas, separadas por vírgulas.\n",
    "Texto da avaliação: ```{lamp_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "O autor da seguinte avaliação está expressando raiva?\n",
    "A avaliação está delimitada por crases triplas.\n",
    "Dê sua resposta como \"sim\" ou \"não\".\n",
    "Texto da avaliação: ```{lamp_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência de Tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "``` \n",
      "1. Pesquisa recente\n",
      "2. Nível de satisfação\n",
      "3. Departamento mais popular\n",
      "4. Comentários sobre os resultados\n",
      "5. Administração da Segurança Social\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "story = \"\"\"\n",
    "Em uma pesquisa recente realizada pelo governo, funcionários do setor público foram convidados a avaliar seu nível de satisfação com o departamento em que trabalham.\n",
    "Os resultados revelaram que a NASA foi o departamento mais popular com uma classificação de satisfação de 95%.\n",
    "\n",
    "Um funcionário da NASA, João da Silva, comentou sobre os resultados, afirmando: \"Não estou surpreso que a NASA esteja no topo.\n",
    "É um ótimo lugar para trabalhar com pessoas incríveis e oportunidades incríveis. Tenho orgulho de fazer parte de uma organização tão inovadora.\"\n",
    "\n",
    "Os resultados também foram bem recebidos pela equipe de gestão da NASA, com o diretor Tom Jonhson afirmando: \"Estamos estusiasmados em ouvir que nossos funcionários estão satisfeitos com a nossa gestão\".\n",
    "Temos uma equipe talentosa e dedicada que trabalha incansavelmente para alcançar nossos objetivos, e é fantástico ver que seu trabalho árduo está dando frutos.\n",
    "\n",
    "A pesquisa também revelou que a Administração da Segurança Social teve a classificação de satisfação mais baixa, com apenas 45% dos funcionários indicando que estavam satisfeitos.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Determine cinco tópicos que estão sendo discutidos no seguinte texto, delimitando por crases triplas.\n",
    "Faça cada item ter uma ou duas palavras.\n",
    "Formate sua resposta como uma lista de itens separados por vírgulas.\n",
    "Texto: ```{story}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração de Informações e Metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Item\": \"lâmpada\",\n",
      "  \"Marca\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifique os seguintess itens do texto da avaliação:\n",
    "- Item comprado pelo cliente\n",
    "- Empresa que fabricou o item\n",
    "O texto da avaliação está delimitado por crases triplas.\n",
    "Formate sua resposta como um objeto JSON com \"Item\" e \"Marca\" com chaves.\n",
    "Se a informação não estiver presente, use \"desconhecido\" como valor.\n",
    "Mantenha sua resposta o mais curta possível.\n",
    "TExto da avaliação: ```{lamp_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Sentimento\": \"positivo\",\n",
      "    \"Raiva\": false,\n",
      "    \"Item\": \"lâmpada\",\n",
      "    \"Marca\": \"Lumina\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifique os seguintes itens do texto da avaliação:\n",
    "\n",
    "- Sentimento (positivo ou negativo)\n",
    "- O autor está expressando raiva? (verdadeiro ou falso)\n",
    "- Item comprado pelo cliente\n",
    "- Empresa que fabricou o item\n",
    "\n",
    "O texto da avaliação está delimitado por crases triplas.\n",
    "\n",
    "Formate sua resposta com um objeto JSON com \"Sentimento\", \"Raiva\", \"Item\" e \"Marca\" com chaves.\n",
    "Se a informação não estiver presente, use \"null\" como valor.\n",
    "Formate o valor de Raiva como booleano.\n",
    "Texto da avaliação: ```{lamp_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
